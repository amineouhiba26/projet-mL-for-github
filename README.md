

# Classification d'accessoires √©lectroniques

*Classer automatiquement des chargeurs, smartphones, claviers et autres accessoires √† partir d'images.*

## Pr√©sentation du projet

Ce projet permet de classer automatiquement des images d'accessoires √©lectroniques en diff√©rentes cat√©gories (smartphone, chargeur, etc.). Il s'appuie sur TensorFlow pour l'apprentissage automatique, utilise l'architecture de r√©seau de neurones EfficientNet pour la reconnaissance d'images, et propose une interface web conviviale gr√¢ce √† Streamlit. L'objectif est de fournir un outil simple qui facilite l'identification d'accessoires √©lectroniques √† partir de photos.

## Structure du projet

La structure du projet est organis√©e de mani√®re claire¬†:

- **`dataset/`** : contient le jeu de donn√©es d'images, avec un sous-dossier par classe d'accessoire (par exemple, `Smartphone/`, `Laptop/`, etc.).
- **`train_model.py`** : script Python pour l'entra√Ænement du mod√®le de classification (bas√© sur EfficientNet).
- **`app.py`** : application web Streamlit pour effectuer des pr√©dictions sur de nouvelles images √† l'aide du mod√®le entra√Æn√©.
- **`requirements.txt`** : liste des d√©pendances Python n√©cessaires pour ex√©cuter le projet.

## Installation et utilisation

Pour utiliser ce projet en local, suivez ces √©tapes simples¬†:

1. **Installer les d√©pendances¬†:** Assurez-vous d'avoir Python install√©, puis installez les biblioth√®ques requises avec la commande¬†:  
    ```bash
    pip install -r requirements.txt
    ```  
    Cette commande installe TensorFlow, Streamlit et toutes les autres d√©pendances list√©es dans le fichier `requirements.txt`.

2. **Pr√©parer le jeu de donn√©es¬†:** Placez vos images d'entra√Ænement dans le dossier `dataset/`, organis√©es par cat√©gorie. Par exemple, mettez toutes les photos de smartphones dans `dataset/Smartphone/`, celles de chargeurs dans `dataset/Charger/`, et ainsi de suite pour chaque type d'accessoire. Assurez-vous d'avoir une structure avec dix sous-dossiers au total (un par classe).

3. **Entra√Æner le mod√®le¬†:** Lancez l'entra√Ænement du mod√®le en ex√©cutant le script Python¬†:  
    ```bash
    python train_model.py
    ```  
    Cette √©tape va charger les images du dataset, entra√Æner le r√©seau de neurones EfficientNet sur ces donn√©es et sauvegarder le mod√®le entra√Æn√© (pr√™t pour la pr√©diction).

4. **Lancer la pr√©diction (interface Streamlit)¬†:** D√©marrez l'application web de pr√©diction avec la commande¬†:  
    ```bash
    streamlit run app.py
    ```  
    Cela ouvrira une interface web interactive dans votre navigateur. Vous pourrez alors charger une image d'accessoire √©lectronique, et le mod√®le affichera la cat√©gorie pr√©dite (par exemple *Smartphone*, *Clavier*, etc.) pour cette image.

## üìä Description du Dataset

Le jeu de donn√©es utilis√© pour entra√Æner le mod√®le comprend des images vari√©es d'accessoires √©lectroniques, r√©parties en dix cat√©gories. Voici quelques caract√©ristiques cl√©s de ce dataset¬†:

- **Objectif¬†:** Fournir un ensemble de donn√©es pour faciliter la recherche en classification d'accessoires √©lectroniques.
- **Nombre de classes¬†:** 10 cat√©gories d'accessoires (chargeur, manette de jeu, casque audio, clavier, ordinateur portable, √©cran, souris, smartphone, montre connect√©e et enceinte).
- **Nombre d'images¬†:** 14‚ÄØ027 images au total, dont 4‚ÄØ027 photos originales et 10‚ÄØ000 images g√©n√©r√©es par augmentation.
- **Format des fichiers¬†:** Images au format PNG.
- **Vari√©t√© des prises de vue¬†:** Les photos ont √©t√© captur√©es sous divers angles et conditions de luminosit√© pour chaque type d'accessoire.
- **Augmentations des donn√©es¬†:** Des transformations ont √©t√© appliqu√©es aux images (rotation, zoom, changements de luminosit√©/contraste, etc.) afin d'augmenter la taille du dataset et la diversit√© des exemples.
- **Source des images¬†:** Images publiques collect√©es sur des r√©seaux sociaux et des sites de revente en ligne.
- **Applications possibles¬†:** Ce dataset peut servir √† entra√Æner des mod√®les de vision par ordinateur pour des projets de machine learning, d'e-commerce (reconnaissance automatique de produits sur des photos), de gestion d'inventaire ou encore des applications mobiles de reconnaissance d'objets.
- **B√©n√©fices de la diversit√©¬†:** La combinaison d'images r√©elles et augment√©es offre une grande diversit√© de donn√©es, ce qui permet d'entra√Æner des mod√®les plus pr√©cis et plus robustes face √† de nouvelles images.

## Explication du fonctionnement du code

**Entra√Ænement du mod√®le¬†:** Le script `train_model.py` parcourt les images du dossier dataset, les pr√©traite (redimensionnement, normalisation, etc.), puis utilise le mod√®le EfficientNet pour apprendre √† classer chaque image dans la bonne cat√©gorie. EfficientNet est un r√©seau de neurones profond pr√©-entra√Æn√© sur un tr√®s large ensemble d'images (par exemple ImageNet). Dans ce projet, on r√©utilise ce mod√®le existant et on l'entra√Æne √† nouveau sur nos propres images (nos dix cat√©gories d'accessoires) afin de l'adapter √† notre besoin sp√©cifique. Au terme de l'entra√Ænement, un fichier contenant le mod√®le final est enregistr√© sur le disque.

**Pr√©diction et interface¬†:** L'application Streamlit (`app.py`) charge le mod√®le entra√Æn√© pr√©c√©demment et offre une interface web simple pour la pr√©diction. L'utilisateur peut importer une photo d'accessoire √©lectronique qu'il souhaite classer. Une fois l'image envoy√©e, le mod√®le l'analyse et pr√©dit √† quelle cat√©gorie appartient l'accessoire. Le r√©sultat (par exemple "Smartphone" ou "Clavier") s'affiche alors dans l'interface, ce qui permet de v√©rifier facilement la pr√©diction du mod√®le.

## Pr√©requis et d√©pendances

Pour ex√©cuter ce projet, vous aurez besoin de l'environnement et des biblioth√®ques suivants¬†:

- **Python¬†:** Version 3.7 ou sup√©rieure.
- **TensorFlow¬†:** Version 2.x (par exemple TensorFlow 2.8) pour l'entra√Ænement du mod√®le de deep learning.
- **Streamlit¬†:** Biblioth√®que pour ex√©cuter l'application web interactive.
- **Pillow (PIL)¬†:** Biblioth√®que d'imagerie Python pour le chargement et le traitement des images (souvent install√©e avec TensorFlow).
- **Autres d√©pendances¬†:** Par exemple NumPy (consultez le fichier `requirements.txt` pour la liste compl√®te des packages requis).

``` mermaid
flowchart TD
    %% Pr√©paration des Donn√©es
    subgraph DP [Pr√©paration des Donn√©es]
        direction TB
        A1[Chargement des images]
        A2[Redimension √† 224x224]
        A3[Encodage des √©tiquettes one-hot]
        A1 --> A2 --> A3
    end

    %% Entra√Ænement
    subgraph MT [Entra√Ænement du Mod√®le]
        direction TB
        B1[Chargement EfficientNetB0]
        B2[Ajout couche Dense pour 10 classes]
        B3[Gel des couches de base]
        B4[Compilation avec poids de classes]
        B5[Entra√Ænement avec EarlyStopping et ModelCheckpoint]
        B1 --> B2 --> B3 --> B4 --> B5
    end

    DP ---> MT
    B5 --> B6[Sauvegarde mod√®le au format .keras]

    %% Conversion
    C[Conversion en TFLite]
    B6 --> C
    C --> D[Fichier .tflite g√©n√©r√©]

    %% Pr√©diction
    subgraph INF [D√©ploiement et Pr√©diction]
        direction TB
        User((Utilisateur))
        P1[T√©l√©verse une image]
        P2[Pr√©traitement resize normalise float32]
        P3[Chargement du mod√®le TFLite]
        P4[Inf√©rence sur l'image]
        P5[Softmax et score de confiance]
        User --> P1 --> P2 --> P3 --> P4 --> P5
    end

    D --> P3
    P5 --> F[Affichage du r√©sultat]

    %% Classes disponibles
    subgraph Classes [Classes disponibles]
        direction TB
        class1[Chargeur]
        class2[Manette de jeu]
        class3[Casque audio]
        class4[Clavier]
        class5[Ordinateur portable]
        class6[√âcran]
        class7[Souris]
        class8[Smartphone]
        class9[Montre connect√©e]
        class10[baffle]
    end

    F --> class1
    F --> class2
    F --> class3
    F --> class4
    F --> class5
    F --> class6
    F --> class7
    F --> class8
    F --> class9
    F --> class10
```
```mermaid
sequenceDiagram
    participant Utilisateur
    participant App as Application Streamlit
    participant Modele as Mod√®le TFLite
    Utilisateur->>App: T√©l√©verse une image
    App->>App: Pr√©traitement (224x224, normalisation)
    App->>Modele: Envoie pour pr√©diction
    Modele-->>App: Retour des probabilit√©s
    App->>App: Softmax + extraction classe
    App-->>Utilisateur: Affiche classe + confiance
```

accuracy/epochs

<img src="accuracy.png" widh="400px"/>


loss/epochs

<img src="loss.png" widh="400px"/>






## Auteur

Ce projet a √©t√© r√©alis√© par **Arij Bettaieb** et **Amine Ouhiba** . correct it if needed